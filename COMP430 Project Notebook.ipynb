{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c9eccd3b",
      "metadata": {
        "id": "c9eccd3b"
      },
      "source": [
        "Import the required libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80d14f29",
      "metadata": {
        "id": "80d14f29"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.optim import SGD\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from opacus import PrivacyEngine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "1K6uC4x6gQen"
      },
      "id": "1K6uC4x6gQen"
    },
    {
      "cell_type": "markdown",
      "id": "5871106a",
      "metadata": {
        "id": "5871106a"
      },
      "source": [
        "Read the data. The read_excel function deemed the file as a .csv file instead of an Excel file so I had to use the\n",
        "read_csv function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7215c9f",
      "metadata": {
        "id": "f7215c9f"
      },
      "outputs": [],
      "source": [
        "file_path = \"./healthcare-dataset-stroke-data.csv.xls\"\n",
        "stroke_data = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bc59394",
      "metadata": {
        "id": "3bc59394"
      },
      "source": [
        "The target column of our data is the \"stroke\" column, which is 0 if the subject hasn't had a stroke, and 1 if the patient has had a stroke. I dropped the data points that include NaN values, which dropped around 200 data points.\n",
        "\n",
        "Finally, I dropped the id feature as it is completely useless."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abd8a806",
      "metadata": {
        "id": "abd8a806"
      },
      "outputs": [],
      "source": [
        "target_column = \"stroke\"\n",
        "stroke_data.dropna(inplace= True)\n",
        "stroke_data = stroke_data.drop(columns=\"id\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39e96e15",
      "metadata": {
        "id": "39e96e15"
      },
      "source": [
        "Find the numerical and categorical columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee84dbc5",
      "metadata": {
        "id": "ee84dbc5"
      },
      "outputs": [],
      "source": [
        "numerical_columns = stroke_data.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
        "categorical_columns = stroke_data.select_dtypes(include=[\"object\"]).columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d6faadb",
      "metadata": {
        "id": "9d6faadb"
      },
      "source": [
        "Encode the categorical data using one hot encoding with the pandas library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eb73893",
      "metadata": {
        "scrolled": true,
        "id": "1eb73893",
        "outputId": "ba57e009-6b8f-40e0-8c4a-cbff1cadae99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    age  hypertension  heart_disease  avg_glucose_level   bmi  stroke  \\\n",
            "0  67.0             0              1             228.69  36.6       1   \n",
            "2  80.0             0              1             105.92  32.5       1   \n",
            "3  49.0             0              0             171.23  34.4       1   \n",
            "4  79.0             1              0             174.12  24.0       1   \n",
            "5  81.0             0              0             186.21  29.0       1   \n",
            "\n",
            "   gender_Male  gender_Other  ever_married_Yes  work_type_Never_worked  \\\n",
            "0         True         False              True                   False   \n",
            "2         True         False              True                   False   \n",
            "3        False         False              True                   False   \n",
            "4        False         False              True                   False   \n",
            "5         True         False              True                   False   \n",
            "\n",
            "   work_type_Private  work_type_Self-employed  work_type_children  \\\n",
            "0               True                    False               False   \n",
            "2               True                    False               False   \n",
            "3               True                    False               False   \n",
            "4              False                     True               False   \n",
            "5               True                    False               False   \n",
            "\n",
            "   Residence_type_Urban  smoking_status_formerly smoked  \\\n",
            "0                  True                            True   \n",
            "2                 False                           False   \n",
            "3                  True                           False   \n",
            "4                 False                           False   \n",
            "5                  True                            True   \n",
            "\n",
            "   smoking_status_never smoked  smoking_status_smokes  \n",
            "0                        False                  False  \n",
            "2                         True                  False  \n",
            "3                        False                   True  \n",
            "4                         True                  False  \n",
            "5                        False                  False  \n",
            "               age  hypertension  heart_disease  avg_glucose_level  \\\n",
            "count  4909.000000   4909.000000    4909.000000        4909.000000   \n",
            "mean     42.865374      0.091872       0.049501         105.305150   \n",
            "std      22.555115      0.288875       0.216934          44.424341   \n",
            "min       0.080000      0.000000       0.000000          55.120000   \n",
            "25%      25.000000      0.000000       0.000000          77.070000   \n",
            "50%      44.000000      0.000000       0.000000          91.680000   \n",
            "75%      60.000000      0.000000       0.000000         113.570000   \n",
            "max      82.000000      1.000000       1.000000         271.740000   \n",
            "\n",
            "               bmi       stroke  \n",
            "count  4909.000000  4909.000000  \n",
            "mean     28.893237     0.042575  \n",
            "std       7.854067     0.201917  \n",
            "min      10.300000     0.000000  \n",
            "25%      23.500000     0.000000  \n",
            "50%      28.100000     0.000000  \n",
            "75%      33.100000     0.000000  \n",
            "max      97.600000     1.000000  \n"
          ]
        }
      ],
      "source": [
        "stroke_data_encoded = pd.get_dummies(stroke_data, columns= categorical_columns, drop_first= True)\n",
        "\n",
        "print(stroke_data_encoded.head())\n",
        "print(stroke_data_encoded.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the SMOTE strategy to oversample the minority class, so that the data is more heterogeneous."
      ],
      "metadata": {
        "id": "FqS291E-6aNP"
      },
      "id": "FqS291E-6aNP"
    },
    {
      "cell_type": "markdown",
      "id": "3f01d9ab",
      "metadata": {
        "id": "3f01d9ab"
      },
      "source": [
        "Prepare the data matrix and the label vector, plus the training and testing sets. The train-test split is 80%-20%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc19fac2",
      "metadata": {
        "id": "fc19fac2"
      },
      "outputs": [],
      "source": [
        "X = stroke_data_encoded.drop(columns= target_column)\n",
        "y = stroke_data_encoded[target_column]\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_balanced, y_balanced = smote.fit_resample(X, y)\n",
        "X_balanced[\"age\"] = X_balanced[\"age\"].astype(int)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size= 0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the data for PyTorch."
      ],
      "metadata": {
        "id": "fe8tmT2gNdPP"
      },
      "id": "fe8tmT2gNdPP"
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle object columns in X_train and X_test\n",
        "X_train_torch = X_train.apply(pd.to_numeric, errors='coerce')\n",
        "X_test_torch = X_test.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Fill NaN values\n",
        "X_train_torch.fillna(0, inplace=True)\n",
        "X_test_torch.fillna(0, inplace=True)\n",
        "\n",
        "# Explicitly convert all columns to a supported dtype before creating the tensor\n",
        "X_train_torch = X_train_torch.astype(np.float32) # Convert all columns to float32\n",
        "X_test_torch = X_test_torch.astype(np.float32)   # Convert all columns to float32\n",
        "\n",
        "# Convert to tensors\n",
        "X_train_tensor = torch.tensor(X_train_torch.values, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test_torch.values, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "BAyYg8345wK_"
      },
      "id": "BAyYg8345wK_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression with Zero Privacy Using SciKit"
      ],
      "metadata": {
        "id": "Lg4WOHs6ghWR"
      },
      "id": "Lg4WOHs6ghWR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a simple logistic regression model for now, using ALL the data points with zero DP and zero FL."
      ],
      "metadata": {
        "id": "VHz3SDN0JxeB"
      },
      "id": "VHz3SDN0JxeB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90339602",
      "metadata": {
        "id": "90339602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "74528f24-36a7-4c5e-e34c-71a184ea9917"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-3 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-3 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-3 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-3 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-3 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "model = LogisticRegression(max_iter= 1000)\n",
        "\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96e95765",
      "metadata": {
        "id": "96e95765"
      },
      "source": [
        "Check the model's accuracy, recall, precision and F1 score on the test data and generate the model's confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4184c42",
      "metadata": {
        "id": "a4184c42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "outputId": "ac5cac1c-71f3-4a74-bbc8-a1299d99c041"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.8734042553191489\n",
            "Recall:  0.872651356993737\n",
            "Precision:  0.8781512605042017\n",
            "F1 Score:  0.875392670157068\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7b43c7763350>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAGwCAYAAACuFMx9AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPYdJREFUeJzt3Xl0VPX9//HXZA8hkxAgGQJJAFmjLAoK426NREwVCtbqN2JExBYDKhQEqiCLgkUFBSO4FVygiFWoIi6ICioRJYo/NiOLmiAkQTEJi9lm7u+PmLFToGaYSYbMfT7OueeYez/3zntaTt55vz+fe6/FMAxDAAAgYAX5OwAAANCwSPYAAAQ4kj0AAAGOZA8AQIAj2QMAEOBI9gAABDiSPQAAAS7E3wF4w+l0av/+/YqOjpbFYvF3OAAADxmGocOHDysxMVFBQQ1Xf1ZUVKiqqsrr64SFhSkiIsIHETWuJp3s9+/fr6SkJH+HAQDwUmFhodq1a9cg166oqFCHlOYqKnF4fS2bzaZvvvmmySX8Jp3so6OjJUmffdpKzZszI4HANCrV7u8QgAZTo2p9pDWu3+cNoaqqSkUlDn2X117W6FPPFeWHnUrp862qqqpI9o2prnXfvHmQor34PxA4nYVYQv0dAtBwfnlge2NMxTaPtqh59Kl/jlNNd7q4SSd7AADqy2E45fDibTAOw+m7YBoZyR4AYApOGXLq1LO9N+f6G71vAAACHJU9AMAUnHLKm0a8d2f7F8keAGAKDsOQwzj1Vrw35/obbXwAAAIclT0AwBTMvECPZA8AMAWnDDlMmuxp4wMAEOCo7AEApkAbHwCAAMdqfAAAELBI9gAAU3D6YPOEw+HQlClT1KFDB0VGRuqMM87QzJkzZfxHh8AwDE2dOlVt2rRRZGSk0tLStGvXLrfrHDp0SJmZmbJarYqNjdWIESN05MgRj2Ih2QMATMHxy2p8bzZP/P3vf9fChQv1+OOPa+fOnfr73/+uOXPmaMGCBa4xc+bM0fz587Vo0SJt2rRJUVFRSk9PV0VFhWtMZmamtm/frrVr12r16tXasGGDbrvtNo9iYc4eAGAKDkNevvXOs/EbN27UoEGDlJGRIUlq3769/vnPf+rTTz+VVFvVP/roo7r33ns1aNAgSdLzzz+vhIQErVq1Stdff7127typt956S5999pn69u0rSVqwYIGuuuoqPfzww0pMTKxXLFT2AAB4oLy83G2rrKw84bjzzz9f69at09dffy1J+vLLL/XRRx9p4MCBkqRvvvlGRUVFSktLc50TExOjfv36KTc3V5KUm5ur2NhYV6KXpLS0NAUFBWnTpk31jpnKHgBgCqcy7/7f50tSUlKS2/777rtP06ZNO278pEmTVF5erm7duik4OFgOh0MPPPCAMjMzJUlFRUWSpISEBLfzEhISXMeKiooUHx/vdjwkJERxcXGuMfVBsgcAmIJTFjlk8ep8SSosLJTVanXtDw8PP+H4FStWaOnSpVq2bJnOPPNMbdmyRXfddZcSExOVlZV1ynGcCpI9AAAesFqtbsn+ZCZMmKBJkybp+uuvlyT16NFD3333nWbPnq2srCzZbDZJUnFxsdq0aeM6r7i4WL1795Yk2Ww2lZSUuF23pqZGhw4dcp1fH8zZAwBMwWl4v3ni2LFjCgpyT7PBwcFyOmsnBDp06CCbzaZ169a5jpeXl2vTpk2y2+2SJLvdrtLSUuXl5bnGvPfee3I6nerXr1+9Y6GyBwCYgsPLNr6n51599dV64IEHlJycrDPPPFNffPGF5s6dq1tuuUWSZLFYdNddd+n+++9X586d1aFDB02ZMkWJiYkaPHiwJKl79+668sorNXLkSC1atEjV1dUaPXq0rr/++nqvxJdI9gAANIgFCxZoypQpuv3221VSUqLExET9+c9/1tSpU11j7r77bh09elS33XabSktLdeGFF+qtt95SRESEa8zSpUs1evRoXX755QoKCtLQoUM1f/58j2KxGEbTfdhveXm5YmJitHNHvKKjmZFAYLo5+UJ/hwA0mBqjWh/o3yorK6vXPPipqMsVG7e3UXMvcsWRw06df+aBBo21oVDZAwBMwWlY5DS8WI3vxbn+RjkMAECAo7IHAJhCYy/QO52Q7AEApuBQkBxeNLQdPoylsZHsAQCmYHg5Z28wZw8AAE5XVPYAAFNgzh4AgADnMILkMLyYs2+yT6WhjQ8AQMCjsgcAmIJTFjm9qHGdarqlPckeAGAKZp6zp40PAECAo7IHAJiC9wv0aOMDAHBaq52z9+JFOLTxAQDA6YrKHgBgCk4vn43PanwAAE5zzNkDABDgnAoy7X32zNkDABDgqOwBAKbgMCxyePGaWm/O9TeSPQDAFBxeLtBz0MYHAACnKyp7AIApOI0gOb1Yje9kNT4AAKc32vgAACBgUdkDAEzBKe9W1Dt9F0qjI9kDAEzB+4fqNN1meNONHAAA1AuVPQDAFLx/Nn7TrY9J9gAAUzDz++xJ9gAAUzBzZd90IwcAAPVCZQ8AMAXvH6rTdOtjkj0AwBSchkVOb+6zb8JvvWu6f6YAAIB6obIHAJiC08s2flN+qA7JHgBgCt6/9a7pJvumGzkAAKgXKnsAgCk4ZJHDiwfjeHOuv5HsAQCmQBsfAAD4VPv27WWxWI7bsrOzJUkVFRXKzs5Wy5Yt1bx5cw0dOlTFxcVu1ygoKFBGRoaaNWum+Ph4TZgwQTU1NR7HQmUPADAFh7xrxTs8HP/ZZ5/J4fj1rG3btumKK67QH//4R0nS2LFj9cYbb+jll19WTEyMRo8erSFDhujjjz+u/TyHQxkZGbLZbNq4caMOHDigm266SaGhoZo1a5ZHsZDsAQCm0Nht/NatW7v9/OCDD+qMM87QJZdcorKyMj377LNatmyZfve730mSFi9erO7du+uTTz5R//799c4772jHjh169913lZCQoN69e2vmzJmaOHGipk2bprCwsHrHQhsfAGAKdS/C8WaTpPLycretsrLyNz+7qqpKL774om655RZZLBbl5eWpurpaaWlprjHdunVTcnKycnNzJUm5ubnq0aOHEhISXGPS09NVXl6u7du3e/TdSfYAAHggKSlJMTExrm327Nm/ec6qVatUWlqqm2++WZJUVFSksLAwxcbGuo1LSEhQUVGRa8x/Jvq643XHPEEbHwBgCoaX77M3fjm3sLBQVqvVtT88PPw3z3322Wc1cOBAJSYmnvLne4NkDwAwBV+9z95qtbol+9/y3Xff6d1339Wrr77q2mez2VRVVaXS0lK36r64uFg2m8015tNPP3W7Vt1q/box9UUbHwCABrR48WLFx8crIyPDta9Pnz4KDQ3VunXrXPvy8/NVUFAgu90uSbLb7dq6datKSkpcY9auXSur1arU1FSPYqCyBwCYgj9ecet0OrV48WJlZWUpJOTXlBsTE6MRI0Zo3LhxiouLk9Vq1ZgxY2S329W/f39J0oABA5Samqphw4Zpzpw5Kioq0r333qvs7Ox6TR38J5I9AMAUHF6+9e5Uzn333XdVUFCgW2655bhj8+bNU1BQkIYOHarKykqlp6friSeecB0PDg7W6tWrNWrUKNntdkVFRSkrK0szZszwOA6SPQAADWTAgAEyDOOExyIiIpSTk6OcnJyTnp+SkqI1a9Z4HQfJHgBgCv5o458uSPYAAFNwKkhOL9r43pzrb003cgAAUC9U9gAAU3AYFjm8aMV7c66/kewBAKbAnD0AAAHO8PKtd4YX5/pb040cAADUC5U9AMAUHLLI4cWLcLw5199I9gAAU3Aa3s27O0/8bJwmgTY+AAABjsre5JwOaeW8ZOWujFdZSahiE6p04R9LdM0dhbL88gewYUgr5yZr/TKbjpUHq3Pfw7pp1m7ZOlS4XWvLuhZ67bFkFe5sptBwQ137l+nOZ3b64VsB7s7qd0R/vP2gOvc4ppa2Gk27pb1y34pxHb9gYKkybvpRnXv8LGucQ6Ou6KK92yOPu073Pkd188QidTvnmBwOae/2SP3t/zqqqoK6qSlwerlAz5tz/Y1kb3JvLGyn919oo1vnfq22XY7p2//XXM+O76xm0TW64pYDkqQ1C9tq7eJEjZz7tVonVejVh1P0yI1n6YF1eQqLqO1rfbampZZM7KShd3+n1AtK5aix6Pv8KH9+NcAloplTe7dH6O1/xum+f3x7wuPbP43ShtdjNfbhfSe8Rvc+R/XA0r1a/ni8nri3rRwOqWNqhQxnAwcPn3HKIqcX8+7enOtvp0Wyz8nJ0UMPPaSioiL16tVLCxYs0HnnnefvsExh92arzh7wo3pf/pMkqXVSpT55rbX2fhkt6YAMQ3rn2ba6ZkyhzhlwSJI0ct7XuqNPP33+Tkv1v+YHOWqkZdM66rp7vtUl1xe7rt22y8/++ErAcTa/b9Xm960nPb7ulThJUkK7qpOO+fO0/Vr1bCuteDzBtW/fngjfBQk0IL/3JF566SWNGzdO9913nz7//HP16tVL6enpKikp8XdoptCpb7l2fByror21v7QKdkRp12dW9bi0NvkfLAhX2cEwpV5Y6jqnmdWhM3of1p682l+e321rrp+KwhUUZGjqwN66s895euSmVO3Lb9bo3wdoCDEtq9W9zzGV/hiiea/t0vIvt+uhV3brzPOO+Ds0eKDuCXrebE2V35P93LlzNXLkSA0fPlypqalatGiRmjVrpn/84x/+Ds0UMm7fp35XH9Tky/poRMfzdd/A3hpwy36d/4eDkqSyg2GSpJhW7hWPtVWVyg6GSpJKCmr/UFg1L1lXjynU2MXbFRVTowev66EjpadF8wjwSpuU2n//w8YV682lLXVPZgft3hqpB1/aq8QOlX6ODvVVN2fvzdZU+TXyqqoq5eXlKS0tzbUvKChIaWlpys3NPW58ZWWlysvL3TZ459PVrfTJqnj9eUG+pq3Zolvnfq03n2qrj16Or/c1DGftX7tXjy7UuVf9qPY9j2rEw7tksUifrW7VUKEDjSbol9+Ua15sqXdeitOebc305LS22rcnXOnXH/JvcEA9+DXZ//DDD3I4HEpISHDbn5CQoKKiouPGz549WzExMa4tKSmpsUINWCse6KCrbt+n/tf8oKRux3TB0INKv3W/Vj/RTpIU07q2oin7IcztvPIfwhTTulqSFBtfOyax869z9KHhhlonV+jH/eGN8TWABvVjcW2H6ruv3efoC3eHK77tyef5cXpxyuJ6Pv4pbU14gV6T6klMnjxZZWVlrq2wsNDfITV5lT8HKSjI/UkRQUGGq1pvnVypmNZV2vFxrOv4z4eDtWdLtM7oU9tZad/jiELCnTqw99dblWqqLfphX7hatXW/PQ9oiooLw/TDgRC1O8P933PbjpUq2Rd2krNwujF+WY1/qpvRhJO9XydUW7VqpeDgYBUXF7vtLy4uls1mO258eHi4wsOpFH2pd9ohvb4gSXGJlWrb5ZgKtjfX28+01UXX1f5/YrFIA0Z8r9fnJ8nW/me1Sq699a5FfJXOGfCjJCky2qHLMg9o1dxktUysVMu2lXrzybaSpHMzfvDbdwPqRDRzKLHDrxW4LalKHc/8WYdLg3Xw+zBFx9aoddtqtUyo7VYl/ZLUfyoJ0U8HQyVZ9K+F8Ro2vkh7d0Rq7/ZIpf3xkJLOqNT9I+P88ZVwCnjrnZ+EhYWpT58+WrdunQYPHixJcjqdWrdunUaPHu3P0Ezjxhl79erDyXrh3jNU/kPtQ3UuzTygQXf+2jW5atT3qvw5WIsnd9Kx8hB16Vuuv76wzXWPvST96Z5vFRxi6Km7uqiqIkhn9D6sif/cpqhYhz++FuCmS6+f9dAre1w//2X6fknSOy+10CNjk9V/QLnGP/rrv/m/LSqQJL3wSIJefKS28Fj5TGuFRjj1l+n7FR3r0N4dEZp8Q0cd+I4CBKc/i2EYfn3a70svvaSsrCw9+eSTOu+88/Too49qxYoV+uqrr46by/9v5eXliomJ0c4d8YqOblIzEkC93Zx8ob9DABpMjVGtD/RvlZWVyWo9+bMQvFGXK/6wdrhCo0592qX6aJVWXrG4QWNtKH6/L+pPf/qTDh48qKlTp6qoqEi9e/fWW2+99ZuJHgAAT9DG97PRo0fTtgcAoIGcFskeAICGxrPxAQAIcGZu47OqDQCAAEdlDwAwBTNX9iR7AIApmDnZ08YHACDAUdkDAEzBzJU9yR4AYAqGvLt9zq+Pm/USyR4AYApmruyZswcAIMBR2QMATMHMlT3JHgBgCmZO9rTxAQAIcFT2AABTMHNlT7IHAJiCYVhkeJGwvTnX32jjAwAQ4KjsAQCmwPvsAQAIcGaes6eNDwBAA/n+++914403qmXLloqMjFSPHj20efNm13HDMDR16lS1adNGkZGRSktL065du9yucejQIWVmZspqtSo2NlYjRozQkSNHPIqDZA8AMIW6BXrebJ746aefdMEFFyg0NFRvvvmmduzYoUceeUQtWrRwjZkzZ47mz5+vRYsWadOmTYqKilJ6eroqKipcYzIzM7V9+3atXbtWq1ev1oYNG3Tbbbd5FAttfACAKfiqjV9eXu62Pzw8XOHh4ceN//vf/66kpCQtXrzYta9Dhw6u/zYMQ48++qjuvfdeDRo0SJL0/PPPKyEhQatWrdL111+vnTt36q233tJnn32mvn37SpIWLFigq666Sg8//LASExPrFTuVPQDAFHxV2SclJSkmJsa1zZ49+4Sf99prr6lv37764x//qPj4eJ199tl6+umnXce/+eYbFRUVKS0tzbUvJiZG/fr1U25uriQpNzdXsbGxrkQvSWlpaQoKCtKmTZvq/d2p7AEA8EBhYaGsVqvr5xNV9ZK0d+9eLVy4UOPGjdPf/vY3ffbZZ7rjjjsUFhamrKwsFRUVSZISEhLczktISHAdKyoqUnx8vNvxkJAQxcXFucbUB8keAGAKhpdt/LrK3mq1uiX7k3E6nerbt69mzZolSTr77LO1bds2LVq0SFlZWaccx6mgjQ8AMAVDkmF4sXn4eW3atFFqaqrbvu7du6ugoECSZLPZJEnFxcVuY4qLi13HbDabSkpK3I7X1NTo0KFDrjH1QbIHAKABXHDBBcrPz3fb9/XXXyslJUVS7WI9m82mdevWuY6Xl5dr06ZNstvtkiS73a7S0lLl5eW5xrz33ntyOp3q169fvWOhjQ8AMAWnLLI04hP0xo4dq/PPP1+zZs3Sddddp08//VRPPfWUnnrqKUmSxWLRXXfdpfvvv1+dO3dWhw4dNGXKFCUmJmrw4MGSajsBV155pUaOHKlFixapurpao0eP1vXXX1/vlfgSyR4AYBKN/SKcc889VytXrtTkyZM1Y8YMdejQQY8++qgyMzNdY+6++24dPXpUt912m0pLS3XhhRfqrbfeUkREhGvM0qVLNXr0aF1++eUKCgrS0KFDNX/+fI9isRiG4ek0xGmjvLxcMTEx2rkjXtHRzEggMN2cfKG/QwAaTI1RrQ/0b5WVldVr0dupqMsVPV8er+BmJ145Xx+OY5X6f398uEFjbShU9gAAU3AaFllM+mx8kj0AwBTqVtV7c35TRe8bAIAAR2UPADCFxl6gdzoh2QMATIFkDwBAgDPzAj3m7AEACHBU9gAAUzDzanySPQDAFGqTvTdz9j4MppHRxgcAIMBR2QMATIHV+AAABDhDnr+T/r/Pb6po4wMAEOCo7AEApkAbHwCAQGfiPj7JHgBgDl5W9mrClT1z9gAABDgqewCAKfAEPQAAApyZF+jRxgcAIMBR2QMAzMGweLfIrglX9iR7AIApmHnOnjY+AAABjsoeAGAOPFQHAIDAZubV+PVK9q+99lq9L3jNNdeccjAAAMD36pXsBw8eXK+LWSwWORwOb+IBAKDhNOFWvDfqleydTmdDxwEAQIMycxvfq9X4FRUVvooDAICGZfhga6I8TvYOh0MzZ85U27Zt1bx5c+3du1eSNGXKFD377LM+DxAAAHjH42T/wAMPaMmSJZozZ47CwsJc+8866yw988wzPg0OAADfsfhga5o8TvbPP/+8nnrqKWVmZio4ONi1v1evXvrqq698GhwAAD5DG7/+vv/+e3Xq1Om4/U6nU9XV1T4JCgAA+I7HyT41NVUffvjhcfv/9a9/6eyzz/ZJUAAA+JyJK3uPn6A3depUZWVl6fvvv5fT6dSrr76q/Px8Pf/881q9enVDxAgAgPdM/NY7jyv7QYMG6fXXX9e7776rqKgoTZ06VTt37tTrr7+uK664oiFiBAAAXjilZ+NfdNFFWrt2ra9jAQCgwZj5Fben/CKczZs3a+fOnZJq5/H79Onjs6AAAPA53npXf/v27dMNN9ygjz/+WLGxsZKk0tJSnX/++Vq+fLnatWvn6xgBAIAXPJ6zv/XWW1VdXa2dO3fq0KFDOnTokHbu3Cmn06lbb721IWIEAMB7dQv0vNmaKI+T/fr167Vw4UJ17drVta9r165asGCBNmzY4NPgAADwFYvh/eaJadOmyWKxuG3dunVzHa+oqFB2drZatmyp5s2ba+jQoSouLna7RkFBgTIyMtSsWTPFx8drwoQJqqmp8fi7e9zGT0pKOuHDcxwOhxITEz0OAACARuGHOfszzzxT7777ruvnkJBf0+7YsWP1xhtv6OWXX1ZMTIxGjx6tIUOG6OOPP5ZUm1czMjJks9m0ceNGHThwQDfddJNCQ0M1a9Ysj+LwuLJ/6KGHNGbMGG3evNm1b/Pmzbrzzjv18MMPe3o5AAACVkhIiGw2m2tr1aqVJKmsrEzPPvus5s6dq9/97nfq06ePFi9erI0bN+qTTz6RJL3zzjvasWOHXnzxRfXu3VsDBw7UzJkzlZOTo6qqKo/iqFeyb9GiheLi4hQXF6fhw4dry5Yt6tevn8LDwxUeHq5+/frp888/1y233OLh/wwAADQSH83Zl5eXu22VlZUn/chdu3YpMTFRHTt2VGZmpgoKCiRJeXl5qq6uVlpammtst27dlJycrNzcXElSbm6uevTooYSEBNeY9PR0lZeXa/v27R599Xq18R999FGPLgoAwGnHR238pKQkt9333Xefpk2bdtzwfv36acmSJeratasOHDig6dOn66KLLtK2bdtUVFSksLAw111tdRISElRUVCRJKioqckv0dcfrjnmiXsk+KyvLo4sCABCoCgsLZbVaXT+Hh4efcNzAgQNd/92zZ0/169dPKSkpWrFihSIjIxs8zv/k8Zz9f6qoqDiunQEAwGnJRy/CsVqtbtvJkv1/i42NVZcuXbR7927ZbDZVVVWptLTUbUxxcbFsNpskyWazHbc6v+7nujH15XGyP3r0qEaPHq34+HhFRUWpRYsWbhsAAKclP7/17siRI9qzZ4/atGmjPn36KDQ0VOvWrXMdz8/PV0FBgex2uyTJbrdr69atKikpcY1Zu3atrFarUlNTPfpsj5P93Xffrffee08LFy5UeHi4nnnmGU2fPl2JiYl6/vnnPb0cAAABafz48Vq/fr2+/fZbbdy4UX/4wx8UHBysG264QTExMRoxYoTGjRun999/X3l5eRo+fLjsdrv69+8vSRowYIBSU1M1bNgwffnll3r77bd17733Kjs7u97dhDoe32f/+uuv6/nnn9ell16q4cOH66KLLlKnTp2UkpKipUuXKjMz09NLAgDQ8Br5Fbd1j5f/8ccf1bp1a1144YX65JNP1Lp1a0nSvHnzFBQUpKFDh6qyslLp6el64oknXOcHBwdr9erVGjVqlOx2u6KiopSVlaUZM2Z4HLrHyf7QoUPq2LGjpNp5i0OHDkmSLrzwQo0aNcrjAAAAaAyn8hS8/z7fE8uXL/+fxyMiIpSTk6OcnJyTjklJSdGaNWs8++AT8LiN37FjR33zzTeSau8JXLFihaTaiv+/byEAAAD+53GyHz58uL788ktJ0qRJk5STk6OIiAiNHTtWEyZM8HmAAAD4hJ8X6PmTx238sWPHuv47LS1NX331lfLy8tSpUyf17NnTp8EBAADveZzs/1tKSopSUlJ8EQsAAA3GIi/n7H0WSeOrV7KfP39+vS94xx13nHIwAADA9+qV7OfNm1evi1ksFr8k+1FnXagQS2ijfy7QGN7en+fvEIAGU37YqRZdGunDGvnWu9NJvZJ93ep7AACaLD+8z/504dWz8QEAwOnP6wV6AAA0CSau7En2AABTaOwn6J1OaOMDABDgqOwBAOZg4jb+KVX2H374oW688UbZ7XZ9//33kqQXXnhBH330kU+DAwDAZ0z8uFyPk/0rr7yi9PR0RUZG6osvvlBlZaUkqaysTLNmzfJ5gAAAwDseJ/v7779fixYt0tNPP63Q0F8fZHPBBRfo888/92lwAAD4St0CPW+2psrjOfv8/HxdfPHFx+2PiYlRaWmpL2ICAMD3TPwEPY8re5vNpt27dx+3/6OPPlLHjh19EhQAAD7HnH39jRw5Unfeeac2bdoki8Wi/fv3a+nSpRo/frxGjRrVEDECAAAveNzGnzRpkpxOpy6//HIdO3ZMF198scLDwzV+/HiNGTOmIWIEAMBrZn6ojsfJ3mKx6J577tGECRO0e/duHTlyRKmpqWrevHlDxAcAgG+Y+D77U36oTlhYmFJTU30ZCwAAaAAeJ/vLLrtMFsvJVyS+9957XgUEAECD8Pb2OTNV9r1793b7ubq6Wlu2bNG2bduUlZXlq7gAAPAt2vj1N2/evBPunzZtmo4cOeJ1QAAAwLd89ta7G2+8Uf/4xz98dTkAAHzLxPfZ++ytd7m5uYqIiPDV5QAA8CluvfPAkCFD3H42DEMHDhzQ5s2bNWXKFJ8FBgAAfMPjZB8TE+P2c1BQkLp27aoZM2ZowIABPgsMAAD4hkfJ3uFwaPjw4erRo4datGjRUDEBAOB7Jl6N79ECveDgYA0YMIC32wEAmhwzv+LW49X4Z511lvbu3dsQsQAAgAbgcbK///77NX78eK1evVoHDhxQeXm52wYAwGnLhLfdSR7M2c+YMUN//etfddVVV0mSrrnmGrfH5hqGIYvFIofD4fsoAQDwlonn7Oud7KdPn66//OUvev/99xsyHgAA4GP1TvaGUfsnzSWXXNJgwQAA0FB4qE49/a+33QEAcFqjjV8/Xbp0+c2Ef+jQIa8CAgAAvuVRsp8+ffpxT9ADAKApoI1fT9dff73i4+MbKhYAABqOidv49b7Pnvl6AACapnon+7rV+AAANEl+fJ/9gw8+KIvForvuusu1r6KiQtnZ2WrZsqWaN2+uoUOHqri42O28goICZWRkqFmzZoqPj9eECRNUU1Pj8efXO9k7nU5a+ACAJstfz8b/7LPP9OSTT6pnz55u+8eOHavXX39dL7/8stavX6/9+/e7vUbe4XAoIyNDVVVV2rhxo5577jktWbJEU6dO9TgGjx+XCwBAk+SHyv7IkSPKzMzU008/7fa22LKyMj377LOaO3eufve736lPnz5avHixNm7cqE8++USS9M4772jHjh168cUX1bt3bw0cOFAzZ85UTk6OqqqqPIqDZA8AgAf++50wlZWVJx2bnZ2tjIwMpaWlue3Py8tTdXW12/5u3bopOTlZubm5kqTc3Fz16NFDCQkJrjHp6ekqLy/X9u3bPYqZZA8AMAcfVfZJSUmKiYlxbbNnzz7hxy1fvlyff/75CY8XFRUpLCxMsbGxbvsTEhJUVFTkGvOfib7ueN0xT3h06x0AAE2Vr+6zLywslNVqde0PDw8/bmxhYaHuvPNOrV27VhEREaf+oT5CZQ8AgAesVqvbdqJkn5eXp5KSEp1zzjkKCQlRSEiI1q9fr/nz5yskJEQJCQmqqqpSaWmp23nFxcWy2WySJJvNdtzq/Lqf68bUF8keAGAOjbhA7/LLL9fWrVu1ZcsW19a3b19lZma6/js0NFTr1q1znZOfn6+CggLZ7XZJkt1u19atW1VSUuIas3btWlmtVqWmpnr01WnjAwBMoTEflxsdHa2zzjrLbV9UVJRatmzp2j9ixAiNGzdOcXFxslqtGjNmjOx2u/r37y9JGjBggFJTUzVs2DDNmTNHRUVFuvfee5WdnX3CbsL/QrIHAMAP5s2bp6CgIA0dOlSVlZVKT0/XE0884ToeHBys1atXa9SoUbLb7YqKilJWVpZmzJjh8WeR7AEA5uDnZ+N/8MEHbj9HREQoJydHOTk5Jz0nJSVFa9as8e6DRbIHAJgFL8IBAACBisoeAGAKll82b85vqkj2AABzMHEbn2QPADCFxrz17nTDnD0AAAGOyh4AYA608QEAMIEmnLC9QRsfAIAAR2UPADAFMy/QI9kDAMzBxHP2tPEBAAhwVPYAAFOgjQ8AQKCjjQ8AAAIVlT0AwBRo4wMAEOhM3MYn2QMAzMHEyZ45ewAAAhyVPQDAFJizBwAg0NHGBwAAgYrKHgBgChbDkMU49fLcm3P9jWQPADAH2vgAACBQUdkDAEyB1fgAAAQ62vgAACBQUdkDAEyBNj4AAIHOxG18kj0AwBTMXNkzZw8AQICjsgcAmANtfAAAAl9TbsV7gzY+AAABjsoeAGAOhlG7eXN+E0WyBwCYAqvxAQBAwKKyBwCYA6vxAQAIbBZn7ebN+U0VbXwAAAIcyR46q99hTV+8W8s2b9Xb+z6XPb3UdSw4xNCIv32vRe/u0L+/3qJlm7dqwqPfKi6hyjUmoV2lxj78nZ7buE2v7f5Ciz/apmF/3a+Q0Cb8ZzAChsMhPTfHppv6ddfVHXvqZnt3LZ2X4Law+oWHbRpxUTddc0YPDe1+liZed4a++rzZcdfa9K5Vd2R01tUde2po97M0bXiHRvwm8Jrhg80DCxcuVM+ePWW1WmW1WmW32/Xmm2+6jldUVCg7O1stW7ZU8+bNNXToUBUXF7tdo6CgQBkZGWrWrJni4+M1YcIE1dTUePzVaeNDEc2c2rujmd5+qZXue2av27HwSKc6nXVMyx5to707ItU81qFR0ws1/R97NSajmyQpqVOFgiyGHpuUrP3fhqt9159115wCRUQ69fT97fzxlQCXFTnxWv1cK41/rEApXSu068tIPTI2WVHRDg2+9QdJUtuOFcp+YJ/apFSpsiJIK59qrck3nKHFG3cotqVDkvThGzF6dEKShk86oN4XHJHDIX37VaQ/vxo81Nir8du1a6cHH3xQnTt3lmEYeu655zRo0CB98cUXOvPMMzV27Fi98cYbevnllxUTE6PRo0dryJAh+vjjjyVJDodDGRkZstls2rhxow4cOKCbbrpJoaGhmjVrloexG/67cXDDhg166KGHlJeXpwMHDmjlypUaPHhwvc8vLy9XTEyMLg0aohBLaMMFaiJv7/tc00Z0VO7bsScd06XXUS14I183nneWDu4PO+GYa/9SrN8PO6ibLzirgSI1j7f35fk7hCZtyk0d1KJVjcbNLXTtm3Fre4VHODXx8YITnnP0cJCGdO2pB1/arbMvOiJHjXRTv1QN+2uRrvy/Q40VuimUH3aqRZe9Kisrk9VqbZjP+CVXnHfNTIWERpzydWqqK/Tpa1NUWFjoFmt4eLjCw8PrdY24uDg99NBDuvbaa9W6dWstW7ZM1157rSTpq6++Uvfu3ZWbm6v+/fvrzTff1O9//3vt379fCQkJkqRFixZp4sSJOnjwoMLCTvz790T82sY/evSoevXqpZycHH+GAQ9FRTvkdEpHy4P/55jDpTSO4H+pfY9qy0fR2ren9pfxnu0R2v5plM793eETjq+usmjNiy0VZXWoY+rPkqRdW5vphwNhsgRJt1/RRTf0PlP3ZHbUt1+deuJA05WUlKSYmBjXNnv27N88x+FwaPny5Tp69Kjsdrvy8vJUXV2ttLQ015hu3bopOTlZubm5kqTc3Fz16NHDleglKT09XeXl5dq+fbtHMfv1t/HAgQM1cODAeo+vrKxUZWWl6+fy8vKGCAv/Q2i4UyP+9r0++HcLHTty4mSf2L5Cg4aX0MLHaeFPo0t07HCwbr24m4KCJadDunnSAf1uyE9u4z5Za9XsUSmq/DlIcQnVmr18t2J+aeEXfVdbQb34iE23TftetqQq/WtRvCYM7aRnP9opawtHo38veM5XbfwTVfYns3XrVtntdlVUVKh58+ZauXKlUlNTtWXLFoWFhSk2NtZtfEJCgoqKiiRJRUVFbom+7njdMU80qQV6s2fPdvtrKikpyd8hmUpwiKF7Fn4jWaQFk5NPOKalrUoPvLhHG95ooTeXtWrkCIHjbXgtVu+92kKTcr5Tztv5Gv9Ygf61KF5rV7RwG9f7giN6Ym2+5r22S30vPawH/txepT/U1kPOX9aa3nBnsS7KKFPnnj/rr/MKZLFIH66ObeRvhFPmowV6dQvu6rb/ley7du2qLVu2aNOmTRo1apSysrK0Y8eOBvqCJ9ekkv3kyZNVVlbm2goLC3/7JPhEcIihexbtVUK7Kk2+ofMJq/q4hCrNWbFLOzZH6bG7T/zHANDYnp6ZqD+NLtGlg0vVoXuF0q79SUNGHtTyBe4VU0Qzp9p2qFL3Psc0bm6hgkOkt/4ZJ0mKS6hd/ZzcucI1PizckC2lUiXfs14IJxcWFqZOnTqpT58+mj17tnr16qXHHntMNptNVVVVKi0tdRtfXFwsm80mSbLZbMetzq/7uW5MfTWpZB8eHn7cX1RoeHWJvm37Sk26vtMJ5+Jb2qr00Mu7tOv/NdMj41JkGBY/RAocr7IiSJYg995tULDxm+80MZxSdWXtr8jOPY8pNNzpmveXpJpqqbgwTAntqn0eMxpGXRvfm81bTqdTlZWV6tOnj0JDQ7Vu3TrXsfz8fBUUFMhut0uS7Ha7tm7dqpKSEteYtWvXymq1KjU11aPPZQUVFNHMocT2v66FsCVVqmPqMR0uDdGhklBNeXKvOvU4pqlZZygoWGrRuvaX2+HSYNVUB7kSfcm+MD19f1vFtPz1HtCfDlL1wL/6X1Gu5fMTFN+2WildK7RnW6RefTJeA67/UZJUcSxIyx5LkH1AmeISqlV+KESvLW6lH4pCddHVpZKkqGinMob9qBcesal1YrXi21XpXwvjJUkX/b7UT98MHmvkt95NnjxZAwcOVHJysg4fPqxly5bpgw8+0Ntvv62YmBiNGDFC48aNU1xcnKxWq8aMGSO73a7+/ftLkgYMGKDU1FQNGzZMc+bMUVFRke69915lZ2fXe/V/HZI91KXXMT308i7Xz3+Z9r0k6Z0VcXpxbhvZ08skSQvXfuV23oQ/dtb/y43WORcdVtsOlWrboVLLNm9zG5Pe7pwGjh74326/f5+em9NGj09up9IfQ9QyoVpXDftBmWNr26FBQYb27Q7XzJfbq/xQiKJbONSl1zE9snKX2nf9tW0/csr3Cg42NOeOZFVVBKnr2cf095f3KDqWxXk4sZKSEt100006cOCAYmJi1LNnT7399tu64oorJEnz5s1TUFCQhg4dqsrKSqWnp+uJJ55wnR8cHKzVq1dr1KhRstvtioqKUlZWlmbMmOFxLH69z/7IkSPavXu3JOnss8/W3LlzddlllykuLk7Jyb8958t99jAD7rNHIGvM++ztA2d4fZ997ptTGzTWhuLXyn7z5s267LLLXD+PGzdOkpSVlaUlS5b4KSoAQEDirXf+cemll8qPjQUAAEyBOXsAgCk09rPxTyckewCAOTiN2s2b85sokj0AwBxMPGffpB6qAwAAPEdlDwAwBYu8nLP3WSSNj2QPADCHRn6C3umENj4AAAGOyh4AYArcegcAQKBjNT4AAAhUVPYAAFOwGIYsXiyy8+ZcfyPZAwDMwfnL5s35TRRtfAAAAhyVPQDAFGjjAwAQ6Ey8Gp9kDwAwB56gBwAAAhWVPQDAFHiCHgAAgY42PgAACFRU9gAAU7A4azdvzm+qSPYAAHOgjQ8AAAIVlT0AwBx4qA4AAIHNzI/LpY0PAECAo7IHAJiDiRfokewBAOZgyLt30jfdXE+yBwCYA3P2AAAgYFHZAwDMwZCXc/Y+i6TRkewBAOZg4gV6tPEBAAhwVPYAAHNwSrJ4eX4TRbIHAJgCq/EBAEDAorIHAJiDiRfokewBAOZg4mRPGx8AgAYwe/ZsnXvuuYqOjlZ8fLwGDx6s/Px8tzEVFRXKzs5Wy5Yt1bx5cw0dOlTFxcVuYwoKCpSRkaFmzZopPj5eEyZMUE1NjUexkOwBAOZQV9l7s3lg/fr1ys7O1ieffKK1a9equrpaAwYM0NGjR11jxo4dq9dff10vv/yy1q9fr/3792vIkCGu4w6HQxkZGaqqqtLGjRv13HPPacmSJZo6dapHsVgMo+n2JcrLyxUTE6NLg4YoxBLq73CABvH2vjx/hwA0mPLDTrXosldlZWWyWq0N8xm/5IrLu/5VIcHhp3ydGkel1uU/csqxHjx4UPHx8Vq/fr0uvvhilZWVqXXr1lq2bJmuvfZaSdJXX32l7t27Kzc3V/3799ebb76p3//+99q/f78SEhIkSYsWLdLEiRN18OBBhYWF1euzqewBAKZQd+udN5tU+8fDf26VlZX1+vyysjJJUlxcnCQpLy9P1dXVSktLc43p1q2bkpOTlZubK0nKzc1Vjx49XIlektLT01VeXq7t27fX+7uT7AEA8EBSUpJiYmJc2+zZs3/zHKfTqbvuuksXXHCBzjrrLElSUVGRwsLCFBsb6zY2ISFBRUVFrjH/mejrjtcdqy9W4wMAzMFHq/ELCwvd2vjh4b89NZCdna1t27bpo48+OvXP9wLJHgBgDk5DsniR7J2151qtVo/m7EePHq3Vq1drw4YNateunWu/zWZTVVWVSktL3ar74uJi2Ww215hPP/3U7Xp1q/XrxtQHbXwAABqAYRgaPXq0Vq5cqffee08dOnRwO96nTx+FhoZq3bp1rn35+fkqKCiQ3W6XJNntdm3dulUlJSWuMWvXrpXValVqamq9Y6GyBwCYQyM/VCc7O1vLli3Tv//9b0VHR7vm2GNiYhQZGamYmBiNGDFC48aNU1xcnKxWq8aMGSO73a7+/ftLkgYMGKDU1FQNGzZMc+bMUVFRke69915lZ2fXa/qgDskeAGASXiZ7eXbuwoULJUmXXnqp2/7Fixfr5ptvliTNmzdPQUFBGjp0qCorK5Wenq4nnnjCNTY4OFirV6/WqFGjZLfbFRUVpaysLM2YMcOjWEj2AAA0gPo8xiYiIkI5OTnKyck56ZiUlBStWbPGq1hI9gAAczDxs/FJ9gAAc3Aa8rQVf/z5TROr8QEACHBU9gAAczCctZs35zdRJHsAgDkwZw8AQIBjzh4AAAQqKnsAgDnQxgcAIMAZ8jLZ+yySRkcbHwCAAEdlDwAwB9r4AAAEOKdTkhf3yjub7n32tPEBAAhwVPYAAHOgjQ8AQIAzcbKnjQ8AQICjsgcAmIOJH5dLsgcAmIJhOGV48eY6b871N5I9AMAcDMO76pw5ewAAcLqisgcAmIPh5Zx9E67sSfYAAHNwOiWLF/PuTXjOnjY+AAABjsoeAGAOtPEBAAhshtMpw4s2flO+9Y42PgAAAY7KHgBgDrTxAQAIcE5Dspgz2dPGBwAgwFHZAwDMwTAkeXOffdOt7En2AABTMJyGDC/a+AbJHgCA05zhlHeVPbfeAQCA0xSVPQDAFGjjAwAQ6Ezcxm/Syb7ur6wao9rPkQANp/xw0/0FA/yW8iO1/74bo2quUbVXz9SpUdPNNU062R8+fFiS9JHxulf/BwKnsxZd/B0B0PAOHz6smJiYBrl2WFiYbDabPipa4/W1bDabwsLCfBBV47IYTXgSwul0av/+/YqOjpbFYvF3OKZQXl6upKQkFRYWymq1+jscwKf49934DMPQ4cOHlZiYqKCghlszXlFRoaqqKq+vExYWpoiICB9E1LiadGUfFBSkdu3a+TsMU7JarfwyRMDi33fjaqiK/j9FREQ0ySTtK9x6BwBAgCPZAwAQ4Ej28Eh4eLjuu+8+hYeH+zsUwOf4941A1aQX6AEAgN9GZQ8AQIAj2QMAEOBI9gAABDiSPQAAAY5kj3rLyclR+/btFRERoX79+unTTz/1d0iAT2zYsEFXX321EhMTZbFYtGrVKn+HBPgUyR718tJLL2ncuHG677779Pnnn6tXr15KT09XSUmJv0MDvHb06FH16tVLOTk5/g4FaBDceod66devn84991w9/vjjkmrfS5CUlKQxY8Zo0qRJfo4O8B2LxaKVK1dq8ODB/g4F8Bkqe/ymqqoq5eXlKS0tzbUvKChIaWlpys3N9WNkAID6INnjN/3www9yOBxKSEhw25+QkKCioiI/RQUAqC+SPQAAAY5kj9/UqlUrBQcHq7i42G1/cXGxbDabn6ICANQXyR6/KSwsTH369NG6detc+5xOp9atWye73e7HyAAA9RHi7wDQNIwbN05ZWVnq27evzjvvPD366KM6evSohg8f7u/QAK8dOXJEu3fvdv38zTffaMuWLYqLi1NycrIfIwN8g1vvUG+PP/64HnroIRUVFal3796aP3+++vXr5++wAK998MEHuuyyy47bn5WVpSVLljR+QICPkewBAAhwzNkDABDgSPYAAAQ4kj0AAAGOZA8AQIAj2QMAEOBI9gAABDiSPQAAAY5kDwBAgCPZA166+eabNXjwYNfPl156qe66665Gj+ODDz6QxWJRaWnpScdYLBatWrWq3tecNm2aevfu7VVc3377rSwWi7Zs2eLVdQCcOpI9AtLNN98si8Uii8WisLAwderUSTNmzFBNTU2Df/arr76qmTNn1mtsfRI0AHiLF+EgYF155ZVavHixKisrtWbNGmVnZys0NFSTJ08+bmxVVZXCwsJ88rlxcXE+uQ4A+AqVPQJWeHi4bDabUlJSNGrUKKWlpem1116T9Gvr/YEHHlBiYqK6du0qSSosLNR1112n2NhYxcXFadCgQfr2229d13Q4HBo3bpxiY2PVsmVL3X333frv10v8dxu/srJSEydOVFJSksLDw9WpUyc9++yz+vbbb10vX2nRooUsFotuvvlmSbWvEJ49e7Y6dOigyMhI9erVS//617/cPmfNmjXq0qWLIiMjddlll7nFWV8TJ05Uly5d1KxZM3Xs2FFTpkxRdXX1ceOefPJJJSUlqVmzZrruuutUVlbmdvyZZ55R9+7dFRERoW7duumJJ57wOBYADYdkD9OIjIxUVVWV6+d169YpPz9fa9eu1erVq1VdXa309HRFR0frww8/1Mcff6zmzZvryiuvdJ33yCOPaMmSJfrHP/6hjz76SIcOHdLKlSv/5+fedNNN+uc//6n58+dr586devLJJ9W8eXMlJSXplVdekSTl5+frwIEDeuyxxyRJs2fP1vPPP69FixZp+/btGjt2rG688UatX79eUu0fJUOGDNHVV1+tLVu26NZbb9WkSZM8/t8kOjpaS5Ys0Y4dO/TYY4/p6aef1rx589zG7N69WytWrNDrr7+ut956S1988YVuv/121/GlS5dq6tSpeuCBB7Rz507NmjVLU6ZM0XPPPedxPAAaiAEEoKysLGPQoEGGYRiG0+k01q5da4SHhxvjx493HU9ISDAqKytd57zwwgtG165dDafT6dpXWVlpREZGGm+//bZhGIbRpk0bY86cOa7j1dXVRrt27VyfZRiGcckllxh33nmnYRiGkZ+fb0gy1q5de8I433//fUOS8dNPP7n2VVRUGM2aNTM2btzoNnbEiBHGDTfcYBiGYUyePNlITU11Oz5x4sTjrvXfJBkrV6486fGHHnrI6NOnj+vn++67zwgODjb27dvn2vfmm28aQUFBxoEDBwzDMIwzzjjDWLZsmdt1Zs6cadjtdsMwDOObb74xJBlffPHFST8XQMNizh4Ba/Xq1WrevLmqq6vldDr1f//3f5o2bZrreI8ePdzm6b/88kvt3r1b0dHRbtepqKjQnj17VFZWpgMHDqhfv36uYyEhIerbt+9xrfw6W7ZsUXBwsC655JJ6x717924dO3ZMV1xxhdv+qqoqnX322ZKknTt3usUhSXa7vd6fUeell17S/PnztWfPHh05ckQ1NTWyWq1uY5KTk9W2bVu3z3E6ncrPz1d0dLT27NmjESNGaOTIka4xNTU1iomJ8TgeAA2DZI+Addlll2nhwoUKCwtTYmKiQkLc/7lHRUW5/XzkyBH16dNHS5cuPe5arVu3PqUYIiMjPT7nyJEjkqQ33njDLclKtesQfCU3N1eZmZmaPn260tPTFRMTo+XLl+uRRx7xONann376uD8+goODfRYrAO+Q7BGwoqKi1KlTp3qPP+ecc/TSSy8pPj7+uOq2Tps2bbRp0yZdfPHFkmor2Ly8PJ1zzjknHN+jRw85nU6tX79eaWlpxx2v6yw4HA7XvtTUVIWHh6ugoOCkHYHu3bu7FhvW+eSTT377S/6HjRs3KiUlRffcc49r33fffXfcuIKCAu3fv1+JiYmuzwkKClLXrl2VkJCgxMRE7d27V5mZmR59PoDGwwI94BeZmZlq1aqVBg0apA8//FDffPONPvjgA91xxx3at2+fJOnOO+/Ugw8+qFWrVumrr77S7bff/j/vkW/fvr2ysrJ0yy23aNWqVa5rrlixQpKUkpIii8Wi1atX6+DBgzpy5Iiio6M1fvx4jR07Vs8995z27Nmjzz//XAsWLHAtevvLX/6iXbt2acKECcrPz9eyZcu0ZMkSj75v586dVVBQoOXLl2vPnj2aP3/+CRcbRkREKCsrS19++aU+/PBD3XHHHbruuutks9kkSdOnT9fs2bM1f/58ff3119q6dasWL16suXPnehQPgIZDsgd+0axZM23YsEHJyckaMmSIunfvrhEjRqiiosJV6f/1r3/VsGHDlJWVJbvdrujoaP3hD3/4n9dduHChrr32Wt1+++3q1q2bRo4cqaNHj0qS2rZtq+nTp2vSpElKSEjQ6NGjJUkzZ87UlClTNHv2bHXv3l1XXnml3njjDXXo0EFS7Tz6K6+8olWrVqlXr15atGiRZs2a5dH3veaaazR27FiNHj1avXv31saNGzVlypTjxnXq1ElDhgzRVVddpQEDBqhnz55ut9bdeuuteuaZZ7R48WL16NFDl1xyiZYsWeKKFYD/WYyTrSwCAAABgcoeAIAAR7IHACDAkewBAAhwJHsAAAIcyR4AgABHsgcAIMCR7AEACHAkewAAAhzJHgCAAEeyBwAgwJHsAQAIcP8fCFbjQPY1Be4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
        "print(\"Recall: \", recall_score(y_test, y_pred))\n",
        "print(\"Precision: \", precision_score(y_test, y_pred))\n",
        "print(\"F1 Score: \", f1_score(y_test, y_pred))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "ConfusionMatrixDisplay(cm).plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementing DP on the Logistic Regression Model (PyTorch)**"
      ],
      "metadata": {
        "id": "oIAAm746cYZV"
      },
      "id": "oIAAm746cYZV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining logistic regression for PyTorch"
      ],
      "metadata": {
        "id": "AHPfXztVMm3p"
      },
      "id": "AHPfXztVMm3p"
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegressionModel(torch.nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.linear = torch.nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.sigmoid(self.linear(x))\n",
        "\n",
        "# Initialize model\n",
        "input_dim = X_train.shape[1]\n",
        "model = LogisticRegressionModel(input_dim)"
      ],
      "metadata": {
        "id": "uVKpaxFW51Nb"
      },
      "id": "uVKpaxFW51Nb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training function for the logistic regression model."
      ],
      "metadata": {
        "id": "JIMZn_pEcisn"
      },
      "id": "JIMZn_pEcisn"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the optimizer and Privacy Engine\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "# Training loop\n",
        "def train_logistic_regression(model, optimizer, criterion, train_loader, target_epsilon, epochs=5):\n",
        "    privacy_engine = PrivacyEngine()\n",
        "\n",
        "    model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
        "    module=model,\n",
        "    optimizer=optimizer,\n",
        "    data_loader=train_loader,\n",
        "    max_grad_norm=1.0,\n",
        "    epochs=5,\n",
        "    target_epsilon = target_epsilon,\n",
        "    target_delta = 1e-5,\n",
        ")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(X_batch).squeeze()\n",
        "            loss = criterion(y_pred, y_batch.float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    epsilon = privacy_engine.get_epsilon(1e-5)\n",
        "    print(f\"Privacy budget spent: ε = {epsilon:.2f}\\n\")\n",
        "    accuracy, precision, recall, f1 = evaluate_logistic_regression(model, test_loader)\n",
        "    print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\\n\")"
      ],
      "metadata": {
        "id": "gwcCJDckJVqL"
      },
      "id": "gwcCJDckJVqL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to evaluate the performance of the LR model."
      ],
      "metadata": {
        "id": "wamfzafHe5JR"
      },
      "id": "wamfzafHe5JR"
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_logistic_regression(model, test_loader):\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            outputs = model(X_batch).squeeze()\n",
        "            predictions = (outputs > 0.5).int()\n",
        "            y_true.extend(y_batch.tolist())\n",
        "            y_pred.extend(predictions.tolist())\n",
        "\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    return accuracy, precision, recall, f1"
      ],
      "metadata": {
        "id": "A4I-7OSIe5bL"
      },
      "id": "A4I-7OSIe5bL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trains and evaluates the LR model's performance with DP using epsilon values from 0.1 to 0.9."
      ],
      "metadata": {
        "id": "hwCLotWgfL_x"
      },
      "id": "hwCLotWgfL_x"
    },
    {
      "cell_type": "code",
      "source": [
        "for epsilon in range(1,10):\n",
        "  # Initialize model\n",
        "    epsilon /= 10\n",
        "    input_dim = X_train.shape[1]\n",
        "    model = LogisticRegressionModel(input_dim)\n",
        "    criterion = torch.nn.BCELoss()\n",
        "    model = LogisticRegressionModel(X_train_tensor.shape[1])\n",
        "    optimizer = SGD(model.parameters(), lr=0.01)\n",
        "    train_logistic_regression(model, optimizer, criterion, train_loader,epsilon, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7KvR_cjfMU9",
        "outputId": "7106b337-32eb-4be8-ec97-ee4d490a6ed8"
      },
      "id": "Y7KvR_cjfMU9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Privacy budget spent: ε = 0.09\n",
            "\n",
            "Accuracy: 0.6016, Precision: 0.6466, Recall: 0.4812, F1 Score: 0.5518\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Privacy budget spent: ε = 0.20\n",
            "\n",
            "Accuracy: 0.5096, Precision: 0.5096, Recall: 1.0000, F1 Score: 0.6751\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Privacy budget spent: ε = 0.30\n",
            "\n",
            "Accuracy: 0.6447, Precision: 0.6517, Recall: 0.6503, F1 Score: 0.6510\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Privacy budget spent: ε = 0.39\n",
            "\n",
            "Accuracy: 0.7005, Precision: 0.6865, Recall: 0.7589, F1 Score: 0.7209\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Privacy budget spent: ε = 0.49\n",
            "\n",
            "Accuracy: 0.7112, Precision: 0.6878, Recall: 0.7933, F1 Score: 0.7368\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Privacy budget spent: ε = 0.60\n",
            "\n",
            "Accuracy: 0.6761, Precision: 0.7041, Recall: 0.6284, F1 Score: 0.6641\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Privacy budget spent: ε = 0.70\n",
            "\n",
            "Accuracy: 0.6910, Precision: 0.6800, Recall: 0.7432, F1 Score: 0.7102\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Privacy budget spent: ε = 0.80\n",
            "\n",
            "Accuracy: 0.6824, Precision: 0.7026, Recall: 0.6534, F1 Score: 0.6771\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Privacy budget spent: ε = 0.90\n",
            "\n",
            "Accuracy: 0.6223, Precision: 0.6432, Recall: 0.5814, F1 Score: 0.6107\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Separation of Hospitals"
      ],
      "metadata": {
        "id": "2yzuBsp0fXpO"
      },
      "id": "2yzuBsp0fXpO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code is used to separate the data into three different hospital sets, ensuring that it is natural, meaning the number of stroke patients should remain the minority."
      ],
      "metadata": {
        "id": "k1vLJgP2ffUv"
      },
      "id": "k1vLJgP2ffUv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35f8805b",
      "metadata": {
        "id": "35f8805b"
      },
      "outputs": [],
      "source": [
        "def create_hospital_data(file_path, hospital_configs):\n",
        "    \"\"\"\n",
        "    Create hospital datasets with specified sizes and stroke rates\n",
        "\n",
        "    Args:\n",
        "        file_path: Path to the input CSV file\n",
        "        hospital_configs: List of tuples containing (hospital_size, stroke_rate) for each hospital\n",
        "\n",
        "    Returns:\n",
        "        List of pandas DataFrames for each hospital\n",
        "    \"\"\"\n",
        "    data = pd.read_csv(file_path)\n",
        "\n",
        "    stroke_data = data[data['stroke'] == 1]\n",
        "    non_stroke_data = data[data['stroke'] == 0]\n",
        "\n",
        "    hospital_datasets = []\n",
        "\n",
        "    for hospital_size, stroke_rate in hospital_configs:\n",
        "        stroke_count = int(hospital_size * stroke_rate)\n",
        "        non_stroke_count = hospital_size - stroke_count\n",
        "\n",
        "        hospital_stroke = stroke_data.sample(n=stroke_count, random_state=42)\n",
        "        hospital_non_stroke = non_stroke_data.sample(n=non_stroke_count, random_state=42)\n",
        "\n",
        "        hospital_data = pd.concat([hospital_stroke, hospital_non_stroke])\n",
        "        hospital_datasets.append(hospital_data)\n",
        "\n",
        "    return hospital_datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hospital_configs = [\n",
        "    (3000, 0.20),  # Hospital 1: size=3000, stroke_rate=0.20\n",
        "    (2700, 0.15),  # Hospital 2: size=2700, stroke_rate=0.15\n",
        "    (3200, 0.10)   # Hospital 3: size=3200, stroke_rate=0.10\n",
        "]\n",
        "\n",
        "file_path = \"./balanced_stroke_data.csv\"\n",
        "hospital_data = create_hospital_data(file_path, hospital_configs)\n",
        "\n",
        "for i, data in enumerate(hospital_data, 1):\n",
        "    print(f\"Hospital {i}\\n\", data.describe())\n",
        "    print(\"\\n\\n\")"
      ],
      "metadata": {
        "id": "YNygkQNgdZxK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d985de39-aef6-4722-9cf8-0f3a9b0f99b5"
      },
      "id": "YNygkQNgdZxK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hospital 1\n",
            "                age  hypertension  heart_disease  avg_glucose_level  \\\n",
            "count  3000.000000   3000.000000    3000.000000        3000.000000   \n",
            "mean     47.253333      0.082667       0.046667         110.227846   \n",
            "std      22.840426      0.275424       0.210959          49.034773   \n",
            "min       0.000000      0.000000       0.000000          55.120000   \n",
            "25%      30.000000      0.000000       0.000000          77.482500   \n",
            "50%      50.000000      0.000000       0.000000          93.565000   \n",
            "75%      66.000000      0.000000       0.000000         120.007500   \n",
            "max      82.000000      1.000000       1.000000         270.743390   \n",
            "\n",
            "               bmi       stroke  \n",
            "count  3000.000000  3000.000000  \n",
            "mean     29.192880     0.200000  \n",
            "std       7.548688     0.400067  \n",
            "min      11.500000     0.000000  \n",
            "25%      24.200000     0.000000  \n",
            "50%      28.400000     0.000000  \n",
            "75%      33.178893     0.000000  \n",
            "max      92.000000     1.000000  \n",
            "\n",
            "\n",
            "\n",
            "Hospital 2\n",
            "                age  hypertension  heart_disease  avg_glucose_level  \\\n",
            "count  2700.000000   2700.000000    2700.000000        2700.000000   \n",
            "mean     45.986296      0.081481       0.045926         108.610972   \n",
            "std      22.653490      0.273624       0.209363          47.729467   \n",
            "min       0.000000      0.000000       0.000000          55.120000   \n",
            "25%      28.000000      0.000000       0.000000          77.435000   \n",
            "50%      49.000000      0.000000       0.000000          92.713601   \n",
            "75%      64.000000      0.000000       0.000000         117.317753   \n",
            "max      82.000000      1.000000       1.000000         267.382950   \n",
            "\n",
            "               bmi       stroke  \n",
            "count  2700.000000  2700.000000  \n",
            "mean     29.129314     0.150000  \n",
            "std       7.662218     0.357138  \n",
            "min      11.500000     0.000000  \n",
            "25%      24.000000     0.000000  \n",
            "50%      28.400000     0.000000  \n",
            "75%      33.189541     0.000000  \n",
            "max      92.000000     1.000000  \n",
            "\n",
            "\n",
            "\n",
            "Hospital 3\n",
            "                age  hypertension  heart_disease  avg_glucose_level  \\\n",
            "count  3200.000000   3200.000000    3200.000000        3200.000000   \n",
            "mean     44.402813      0.079062       0.043437         107.374046   \n",
            "std      22.530364      0.269878       0.203872          46.612760   \n",
            "min       0.000000      0.000000       0.000000          55.120000   \n",
            "25%      27.000000      0.000000       0.000000          77.160000   \n",
            "50%      46.000000      0.000000       0.000000          92.205000   \n",
            "75%      62.000000      0.000000       0.000000         115.997500   \n",
            "max      82.000000      1.000000       1.000000         267.600000   \n",
            "\n",
            "               bmi       stroke  \n",
            "count  3200.000000  3200.000000  \n",
            "mean     29.027935     0.100000  \n",
            "std       7.731435     0.300047  \n",
            "min      10.300000     0.000000  \n",
            "25%      23.800000     0.000000  \n",
            "50%      28.300000     0.000000  \n",
            "75%      33.100000     0.000000  \n",
            "max      92.000000     1.000000  \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export each hospital dataset\n",
        "for i, data in enumerate(hospital_data, 1):\n",
        "    data.to_csv(f'hospital_{i}_data.csv', index=False)\n",
        "    print(f\"Exported Hospital {i} data to hospital_{i}_data.csv\")"
      ],
      "metadata": {
        "id": "MmTr_oYQeeBN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89d78d25-ee26-47c7-db0d-224cc678958c"
      },
      "id": "MmTr_oYQeeBN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported Hospital 1 data to hospital_1_data.csv\n",
            "Exported Hospital 2 data to hospital_2_data.csv\n",
            "Exported Hospital 3 data to hospital_3_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 3 hospitals are extracted and turned into tensors in PyTorch."
      ],
      "metadata": {
        "id": "EMwXExGdAdcj"
      },
      "id": "EMwXExGdAdcj"
    },
    {
      "cell_type": "code",
      "source": [
        "hospitals_in_torch=[]\n",
        "for hospital in hospital_data:\n",
        "  labels = hospital['stroke']\n",
        "  features = hospital.drop(columns=['stroke'])\n",
        "\n",
        "  X = torch.tensor(features.astype(np.float32).values, dtype=torch.float32)\n",
        "  y = torch.tensor(labels.values, dtype=torch.long)\n",
        "  dataset = TensorDataset(X, y)\n",
        "  hospitals_in_torch.append(dataset)\n",
        "\n"
      ],
      "metadata": {
        "id": "770CDn9N_aL0"
      },
      "id": "770CDn9N_aL0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to train a neural network using Differential Privacy."
      ],
      "metadata": {
        "id": "jnlNGwe0AXqi"
      },
      "id": "jnlNGwe0AXqi"
    },
    {
      "cell_type": "code",
      "source": [
        "def train_with_dp(local_dataset, model, optimizer, criterion, epochs, target_epsilon):\n",
        "    dataloader = DataLoader(local_dataset, batch_size=32, shuffle=True)\n",
        "    privacy_engine = PrivacyEngine()\n",
        "    model, optimizer, dataloader = privacy_engine.make_private_with_epsilon(\n",
        "        module=model,\n",
        "        optimizer=optimizer,\n",
        "        data_loader=dataloader,\n",
        "        max_grad_norm=1.0,\n",
        "        epochs=epochs,\n",
        "        target_epsilon=target_epsilon,\n",
        "        target_delta= 1e-5,\n",
        "    )\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        for X_batch, y_batch in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        # Calculate epsilon and accuracy at the end of each epoch\n",
        "        epsilon = privacy_engine.get_epsilon(delta=1e-5)\n",
        "        accuracy = evaluate_model(model, local_dataset)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "        print(f\"Loss: {epoch_loss / len(dataloader):.6f}\")\n",
        "        print(f\"ε = {epsilon:.2f}, Accuracy: {accuracy:.2f}%\\n\")"
      ],
      "metadata": {
        "id": "OFFPH_9lAwfB"
      },
      "id": "OFFPH_9lAwfB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to evaluate the neural network."
      ],
      "metadata": {
        "id": "bLocxTXTA48s"
      },
      "id": "bLocxTXTA48s"
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataset):\n",
        "    dataloader = DataLoader(dataset, batch_size=32)\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in dataloader:\n",
        "            outputs = model(X_batch)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += y_batch.size(0)\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "    return 100 * correct / total"
      ],
      "metadata": {
        "id": "JnT26So4BB5p"
      },
      "id": "JnT26So4BB5p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 models, corresponding to the local models of each hospital, are trained and evaluated, using epsilon values from 0.1 to 0.9."
      ],
      "metadata": {
        "id": "zwYkp3wRBG6o"
      },
      "id": "zwYkp3wRBG6o"
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "for epsilon in range(1, 10):\n",
        "    epsilon /= 10\n",
        "    for i in range(3):\n",
        "        model = torch.nn.Sequential(\n",
        "            torch.nn.Linear(X.shape[1], 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, 2)\n",
        "        ).to(device)\n",
        "\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "        print(f\"\\nTraining model {i + 1}\")\n",
        "        print(f\"Target Epsilon: {epsilon:.1f}\")\n",
        "\n",
        "\n",
        "        try:\n",
        "            train_with_dp(hospitals_in_torch[i], model, optimizer, criterion, epochs=5, target_epsilon=epsilon)\n",
        "        except ValueError as e:\n",
        "            print(f\"Error training model {i + 1} with epsilon {epsilon:.1f}: {e}\")\n",
        "            print(\"Consider increasing target_delta or reducing target_epsilon.\")\n",
        "            continue  # Move to the next model or epsilon value"
      ],
      "metadata": {
        "id": "Qugc2rrZBKAQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "071f01ab-1054-489a-bfa5-c2ca8dfb9c83"
      },
      "id": "Qugc2rrZBKAQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model 1\n",
            "Target Epsilon: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "Loss: 1.271514\n",
            "ε = 0.04, Accuracy: 80.00%\n",
            "\n",
            "Epoch 2/5\n",
            "Loss: 2.062933\n",
            "ε = 0.06, Accuracy: 80.00%\n",
            "\n",
            "Epoch 3/5\n",
            "Loss: 2.145583\n",
            "ε = 0.07, Accuracy: 80.00%\n",
            "\n",
            "Epoch 4/5\n",
            "Loss: 2.102217\n",
            "ε = 0.08, Accuracy: 80.00%\n",
            "\n",
            "Epoch 5/5\n",
            "Loss: 2.191561\n",
            "ε = 0.09, Accuracy: 80.00%\n",
            "\n",
            "\n",
            "Training model 2\n",
            "Target Epsilon: 0.1\n",
            "Epoch 1/5\n",
            "Loss: 1.687517\n",
            "ε = 0.05, Accuracy: 85.00%\n",
            "\n",
            "Epoch 2/5\n",
            "Loss: 2.016804\n",
            "ε = 0.06, Accuracy: 85.00%\n",
            "\n",
            "Epoch 3/5\n",
            "Loss: 1.899606\n",
            "ε = 0.07, Accuracy: 85.00%\n",
            "\n",
            "Epoch 4/5\n",
            "Loss: 1.875832\n",
            "ε = 0.09, Accuracy: 85.00%\n",
            "\n",
            "Epoch 5/5\n",
            "Loss: 1.782606\n",
            "ε = 0.10, Accuracy: 85.00%\n",
            "\n",
            "\n",
            "Training model 3\n",
            "Target Epsilon: 0.1\n",
            "Epoch 1/5\n",
            "Loss: 1.124870\n",
            "ε = 0.05, Accuracy: 89.84%\n",
            "\n",
            "Epoch 2/5\n",
            "Loss: 1.496655\n",
            "ε = 0.06, Accuracy: 89.97%\n",
            "\n",
            "Epoch 3/5\n",
            "Loss: 1.792804\n",
            "ε = 0.07, Accuracy: 89.97%\n",
            "\n",
            "Epoch 4/5\n",
            "Loss: 1.702673\n",
            "ε = 0.08, Accuracy: 89.97%\n",
            "\n",
            "Epoch 5/5\n",
            "Loss: 1.805626\n",
            "ε = 0.09, Accuracy: 89.97%\n",
            "\n",
            "\n",
            "Training model 1\n",
            "Target Epsilon: 0.2\n",
            "Epoch 1/5\n",
            "Loss: 1.598251\n",
            "ε = 0.09, Accuracy: 80.00%\n",
            "\n",
            "Epoch 2/5\n",
            "Loss: 2.309333\n",
            "ε = 0.12, Accuracy: 80.00%\n",
            "\n",
            "Epoch 3/5\n",
            "Loss: 2.456541\n",
            "ε = 0.15, Accuracy: 80.00%\n",
            "\n",
            "Epoch 4/5\n",
            "Loss: 2.499889\n",
            "ε = 0.17, Accuracy: 80.00%\n",
            "\n",
            "Epoch 5/5\n",
            "Loss: 2.408458\n",
            "ε = 0.19, Accuracy: 80.00%\n",
            "\n",
            "\n",
            "Training model 2\n",
            "Target Epsilon: 0.2\n",
            "Epoch 1/5\n",
            "Loss: 1.972190\n",
            "ε = 0.09, Accuracy: 85.00%\n",
            "\n",
            "Epoch 2/5\n",
            "Loss: 1.376600\n",
            "ε = 0.12, Accuracy: 85.00%\n",
            "\n",
            "Epoch 3/5\n",
            "Loss: 1.413298\n",
            "ε = 0.15, Accuracy: 85.00%\n",
            "\n",
            "Epoch 4/5\n",
            "Loss: 1.473339\n",
            "ε = 0.17, Accuracy: 85.00%\n",
            "\n",
            "Epoch 5/5\n",
            "Loss: 1.489777\n",
            "ε = 0.20, Accuracy: 85.00%\n",
            "\n",
            "\n",
            "Training model 3\n",
            "Target Epsilon: 0.2\n",
            "Epoch 1/5\n",
            "Loss: 1.130769\n",
            "ε = 0.09, Accuracy: 90.00%\n",
            "\n",
            "Epoch 2/5\n",
            "Loss: 1.236990\n",
            "ε = 0.12, Accuracy: 90.00%\n",
            "\n",
            "Epoch 3/5\n",
            "Loss: 1.211604\n",
            "ε = 0.15, Accuracy: 90.00%\n",
            "\n",
            "Epoch 4/5\n",
            "Loss: 1.264265\n",
            "ε = 0.17, Accuracy: 90.00%\n",
            "\n",
            "Epoch 5/5\n",
            "Loss: 1.388911\n",
            "ε = 0.19, Accuracy: 90.00%\n",
            "\n",
            "\n",
            "Training model 1\n",
            "Target Epsilon: 0.3\n",
            "Epoch 1/5\n",
            "Loss: 2.770230\n",
            "ε = 0.13, Accuracy: 80.00%\n",
            "\n",
            "Epoch 2/5\n",
            "Loss: 2.218431\n",
            "ε = 0.18, Accuracy: 80.00%\n",
            "\n",
            "Epoch 3/5\n",
            "Loss: 2.206785\n",
            "ε = 0.23, Accuracy: 80.00%\n",
            "\n",
            "Epoch 4/5\n",
            "Loss: 2.169752\n",
            "ε = 0.26, Accuracy: 80.00%\n",
            "\n",
            "Epoch 5/5\n",
            "Loss: 2.254380\n",
            "ε = 0.29, Accuracy: 80.00%\n",
            "\n",
            "\n",
            "Training model 2\n",
            "Target Epsilon: 0.3\n",
            "Epoch 1/5\n",
            "Loss: 10.121172\n",
            "ε = 0.13, Accuracy: 15.00%\n",
            "\n",
            "Epoch 2/5\n",
            "Loss: 1.235714\n",
            "ε = 0.18, Accuracy: 85.00%\n",
            "\n",
            "Epoch 3/5\n",
            "Loss: 1.358579\n",
            "ε = 0.23, Accuracy: 85.00%\n",
            "\n",
            "Epoch 4/5\n",
            "Loss: 1.529276\n",
            "ε = 0.26, Accuracy: 85.00%\n",
            "\n",
            "Epoch 5/5\n",
            "Loss: 1.632051\n",
            "ε = 0.29, Accuracy: 85.00%\n",
            "\n",
            "\n",
            "Training model 3\n",
            "Target Epsilon: 0.3\n",
            "Epoch 1/5\n",
            "Loss: 1.066893\n",
            "ε = 0.13, Accuracy: 90.00%\n",
            "\n",
            "Epoch 2/5\n",
            "Loss: 1.164108\n",
            "ε = 0.18, Accuracy: 90.00%\n",
            "\n",
            "Epoch 3/5\n",
            "Loss: 1.114902\n",
            "ε = 0.23, Accuracy: 90.00%\n",
            "\n",
            "Epoch 4/5\n",
            "Loss: 1.151129\n",
            "ε = 0.26, Accuracy: 90.00%\n",
            "\n",
            "Epoch 5/5\n",
            "Loss: 1.313554\n",
            "ε = 0.29, Accuracy: 90.00%\n",
            "\n",
            "\n",
            "Training model 1\n",
            "Target Epsilon: 0.4\n",
            "Epoch 1/5\n",
            "Loss: 2.129044\n",
            "ε = 0.18, Accuracy: 80.00%\n",
            "\n",
            "Epoch 2/5\n",
            "Loss: 2.596073\n",
            "ε = 0.25, Accuracy: 80.00%\n",
            "\n",
            "Epoch 3/5\n",
            "Loss: 2.292534\n",
            "ε = 0.30, Accuracy: 80.00%\n",
            "\n",
            "Epoch 4/5\n",
            "Loss: 2.439812\n",
            "ε = 0.35, Accuracy: 80.00%\n",
            "\n",
            "Epoch 5/5\n",
            "Loss: 2.333696\n",
            "ε = 0.39, Accuracy: 80.00%\n",
            "\n",
            "\n",
            "Training model 2\n",
            "Target Epsilon: 0.4\n",
            "Epoch 1/5\n",
            "Loss: 2.536830\n",
            "ε = 0.18, Accuracy: 72.04%\n",
            "\n",
            "Epoch 2/5\n",
            "Loss: 1.263447\n",
            "ε = 0.25, Accuracy: 81.74%\n",
            "\n",
            "Epoch 3/5\n",
            "Loss: 1.449366\n",
            "ε = 0.31, Accuracy: 84.26%\n",
            "\n",
            "Epoch 4/5\n",
            "Loss: 1.624764\n",
            "ε = 0.35, Accuracy: 85.44%\n",
            "\n",
            "Epoch 5/5\n",
            "Loss: 1.695802\n",
            "ε = 0.40, Accuracy: 85.15%\n",
            "\n",
            "\n",
            "Training model 3\n",
            "Target Epsilon: 0.4\n",
            "Epoch 1/5\n",
            "Loss: 0.789775\n",
            "ε = 0.18, Accuracy: 90.00%\n",
            "\n",
            "Epoch 2/5\n",
            "Loss: 1.049744\n",
            "ε = 0.25, Accuracy: 90.00%\n",
            "\n",
            "Epoch 3/5\n",
            "Loss: 1.042961\n",
            "ε = 0.31, Accuracy: 90.00%\n",
            "\n",
            "Epoch 4/5\n",
            "Loss: 1.007706\n",
            "ε = 0.35, Accuracy: 90.00%\n",
            "\n",
            "Epoch 5/5\n",
            "Loss: 0.977987\n",
            "ε = 0.40, Accuracy: 90.00%\n",
            "\n",
            "\n",
            "Training model 1\n",
            "Target Epsilon: 0.5\n",
            "Epoch 1/5\n",
            "Loss: 2.780182\n",
            "ε = 0.23, Accuracy: 80.00%\n",
            "\n",
            "Epoch 2/5\n",
            "Loss: 2.466616\n",
            "ε = 0.31, Accuracy: 80.00%\n",
            "\n",
            "Epoch 3/5\n",
            "Loss: 2.268728\n",
            "ε = 0.38, Accuracy: 80.00%\n",
            "\n",
            "Epoch 4/5\n",
            "Loss: 2.333364\n",
            "ε = 0.44, Accuracy: 80.00%\n",
            "\n",
            "Epoch 5/5\n",
            "Loss: 2.287837\n",
            "ε = 0.50, Accuracy: 80.00%\n",
            "\n",
            "\n",
            "Training model 2\n",
            "Target Epsilon: 0.5\n",
            "Epoch 1/5\n",
            "Loss: 1.456279\n",
            "ε = 0.23, Accuracy: 84.96%\n",
            "\n",
            "Epoch 2/5\n",
            "Loss: 1.997254\n",
            "ε = 0.32, Accuracy: 84.96%\n",
            "\n",
            "Epoch 3/5\n",
            "Loss: 1.924307\n",
            "ε = 0.39, Accuracy: 84.96%\n",
            "\n",
            "Epoch 4/5\n",
            "Loss: 1.958130\n",
            "ε = 0.45, Accuracy: 84.96%\n",
            "\n",
            "Epoch 5/5\n",
            "Loss: 1.766186\n",
            "ε = 0.50, Accuracy: 84.96%\n",
            "\n",
            "\n",
            "Training model 3\n",
            "Target Epsilon: 0.5\n",
            "Epoch 1/5\n",
            "Loss: 1.002610\n",
            "ε = 0.22, Accuracy: 90.00%\n",
            "\n",
            "Epoch 2/5\n",
            "Loss: 1.116878\n",
            "ε = 0.31, Accuracy: 90.00%\n",
            "\n",
            "Epoch 3/5\n",
            "Loss: 1.179088\n",
            "ε = 0.38, Accuracy: 90.00%\n",
            "\n",
            "Epoch 4/5\n",
            "Loss: 1.303350\n",
            "ε = 0.44, Accuracy: 90.00%\n",
            "\n",
            "Epoch 5/5\n",
            "Loss: 1.212103\n",
            "ε = 0.49, Accuracy: 90.00%\n",
            "\n",
            "\n",
            "Training model 1\n",
            "Target Epsilon: 0.6\n",
            "Epoch 1/5\n",
            "Loss: 1.899047\n",
            "ε = 0.27, Accuracy: 76.50%\n",
            "\n",
            "Epoch 2/5\n",
            "Loss: 2.259815\n",
            "ε = 0.38, Accuracy: 80.00%\n",
            "\n",
            "Epoch 3/5\n",
            "Loss: 2.507121\n",
            "ε = 0.46, Accuracy: 80.00%\n",
            "\n",
            "Epoch 4/5\n",
            "Loss: 2.504152\n",
            "ε = 0.53, Accuracy: 80.00%\n",
            "\n",
            "Epoch 5/5\n",
            "Loss: 2.429197\n",
            "ε = 0.59, Accuracy: 80.00%\n",
            "\n",
            "\n",
            "Training model 2\n",
            "Target Epsilon: 0.6\n",
            "Epoch 1/5\n",
            "Loss: 0.937150\n",
            "ε = 0.27, Accuracy: 85.00%\n",
            "\n",
            "Epoch 2/5\n",
            "Loss: 1.417631\n",
            "ε = 0.38, Accuracy: 85.00%\n",
            "\n",
            "Epoch 3/5\n",
            "Loss: 1.461363\n",
            "ε = 0.46, Accuracy: 85.00%\n",
            "\n",
            "Epoch 4/5\n",
            "Loss: 1.494215\n",
            "ε = 0.53, Accuracy: 85.00%\n",
            "\n",
            "Epoch 5/5\n",
            "Loss: 1.502762\n",
            "ε = 0.59, Accuracy: 85.00%\n",
            "\n",
            "\n",
            "Training model 3\n",
            "Target Epsilon: 0.6\n",
            "Epoch 1/5\n",
            "Loss: 1.294334\n",
            "ε = 0.27, Accuracy: 90.00%\n",
            "\n",
            "Epoch 2/5\n",
            "Loss: 1.282254\n",
            "ε = 0.38, Accuracy: 90.00%\n",
            "\n",
            "Epoch 3/5\n",
            "Loss: 1.239556\n",
            "ε = 0.46, Accuracy: 90.00%\n",
            "\n",
            "Epoch 4/5\n",
            "Loss: 1.399387\n",
            "ε = 0.53, Accuracy: 90.00%\n",
            "\n",
            "Epoch 5/5\n",
            "Loss: 1.169443\n",
            "ε = 0.59, Accuracy: 90.00%\n",
            "\n",
            "\n",
            "Training model 1\n",
            "Target Epsilon: 0.7\n",
            "Epoch 1/5\n",
            "Loss: 2.221799\n",
            "ε = 0.33, Accuracy: 80.00%\n",
            "\n",
            "Epoch 2/5\n",
            "Loss: 1.493450\n",
            "ε = 0.45, Accuracy: 80.00%\n",
            "\n",
            "Epoch 3/5\n",
            "Loss: 1.946027\n",
            "ε = 0.54, Accuracy: 80.00%\n",
            "\n",
            "Epoch 4/5\n",
            "Loss: 1.926166\n",
            "ε = 0.63, Accuracy: 80.00%\n",
            "\n",
            "Epoch 5/5\n",
            "Loss: 1.805563\n",
            "ε = 0.70, Accuracy: 80.00%\n",
            "\n",
            "\n",
            "Training model 2\n",
            "Target Epsilon: 0.7\n",
            "Epoch 1/5\n",
            "Loss: 1.256367\n",
            "ε = 0.33, Accuracy: 85.00%\n",
            "\n",
            "Epoch 2/5\n",
            "Loss: 1.441078\n",
            "ε = 0.45, Accuracy: 85.00%\n",
            "\n",
            "Epoch 3/5\n",
            "Loss: 1.470398\n",
            "ε = 0.54, Accuracy: 85.00%\n",
            "\n",
            "Epoch 4/5\n",
            "Loss: 1.472208\n",
            "ε = 0.63, Accuracy: 85.00%\n",
            "\n",
            "Epoch 5/5\n",
            "Loss: 1.519998\n",
            "ε = 0.70, Accuracy: 85.00%\n",
            "\n",
            "\n",
            "Training model 3\n",
            "Target Epsilon: 0.7\n",
            "Epoch 1/5\n",
            "Loss: 4.023133\n",
            "ε = 0.32, Accuracy: 89.59%\n",
            "\n",
            "Epoch 2/5\n",
            "Loss: 1.039288\n",
            "ε = 0.45, Accuracy: 90.00%\n",
            "\n",
            "Epoch 3/5\n",
            "Loss: 1.150224\n",
            "ε = 0.54, Accuracy: 90.00%\n",
            "\n",
            "Epoch 4/5\n",
            "Loss: 1.383140\n",
            "ε = 0.62, Accuracy: 90.00%\n",
            "\n",
            "Epoch 5/5\n",
            "Loss: 1.350318\n",
            "ε = 0.70, Accuracy: 90.00%\n",
            "\n",
            "\n",
            "Training model 1\n",
            "Target Epsilon: 0.8\n",
            "Epoch 1/5\n",
            "Loss: 4.665959\n",
            "ε = 0.38, Accuracy: 80.00%\n",
            "\n",
            "Epoch 2/5\n",
            "Loss: 3.737084\n",
            "ε = 0.51, Accuracy: 80.00%\n",
            "\n",
            "Epoch 3/5\n",
            "Loss: 2.998669\n",
            "ε = 0.62, Accuracy: 80.00%\n",
            "\n",
            "Epoch 4/5\n",
            "Loss: 2.560450\n",
            "ε = 0.71, Accuracy: 80.00%\n",
            "\n",
            "Epoch 5/5\n",
            "Loss: 2.232581\n",
            "ε = 0.79, Accuracy: 80.00%\n",
            "\n",
            "\n",
            "Training model 2\n",
            "Target Epsilon: 0.8\n",
            "Epoch 1/5\n",
            "Loss: 2.827270\n",
            "ε = 0.38, Accuracy: 85.00%\n",
            "\n",
            "Epoch 2/5\n",
            "Loss: 1.338835\n",
            "ε = 0.51, Accuracy: 85.00%\n",
            "\n",
            "Epoch 3/5\n",
            "Loss: 1.668261\n",
            "ε = 0.62, Accuracy: 85.00%\n",
            "\n",
            "Epoch 4/5\n",
            "Loss: 1.729031\n",
            "ε = 0.71, Accuracy: 85.00%\n",
            "\n",
            "Epoch 5/5\n",
            "Loss: 1.736470\n",
            "ε = 0.80, Accuracy: 85.00%\n",
            "\n",
            "\n",
            "Training model 3\n",
            "Target Epsilon: 0.8\n",
            "Epoch 1/5\n",
            "Loss: 0.892492\n",
            "ε = 0.38, Accuracy: 90.00%\n",
            "\n",
            "Epoch 2/5\n",
            "Loss: 1.125888\n",
            "ε = 0.51, Accuracy: 90.00%\n",
            "\n",
            "Epoch 3/5\n",
            "Loss: 1.192447\n",
            "ε = 0.62, Accuracy: 90.00%\n",
            "\n",
            "Epoch 4/5\n",
            "Loss: 1.155784\n",
            "ε = 0.71, Accuracy: 90.00%\n",
            "\n",
            "Epoch 5/5\n",
            "Loss: 1.077006\n",
            "ε = 0.79, Accuracy: 90.00%\n",
            "\n",
            "\n",
            "Training model 1\n",
            "Target Epsilon: 0.9\n",
            "Epoch 1/5\n",
            "Loss: 1.740220\n",
            "ε = 0.44, Accuracy: 80.00%\n",
            "\n",
            "Epoch 2/5\n",
            "Loss: 1.932002\n",
            "ε = 0.59, Accuracy: 80.00%\n",
            "\n",
            "Epoch 3/5\n",
            "Loss: 1.895551\n",
            "ε = 0.70, Accuracy: 80.00%\n",
            "\n",
            "Epoch 4/5\n",
            "Loss: 1.780897\n",
            "ε = 0.81, Accuracy: 80.00%\n",
            "\n",
            "Epoch 5/5\n",
            "Loss: 1.760106\n",
            "ε = 0.90, Accuracy: 80.00%\n",
            "\n",
            "\n",
            "Training model 2\n",
            "Target Epsilon: 0.9\n",
            "Epoch 1/5\n",
            "Loss: 0.883229\n",
            "ε = 0.43, Accuracy: 85.00%\n",
            "\n",
            "Epoch 2/5\n",
            "Loss: 1.253586\n",
            "ε = 0.58, Accuracy: 85.00%\n",
            "\n",
            "Epoch 3/5\n",
            "Loss: 1.445229\n",
            "ε = 0.70, Accuracy: 85.00%\n",
            "\n",
            "Epoch 4/5\n",
            "Loss: 1.382074\n",
            "ε = 0.80, Accuracy: 85.00%\n",
            "\n",
            "Epoch 5/5\n",
            "Loss: 1.569280\n",
            "ε = 0.89, Accuracy: 85.00%\n",
            "\n",
            "\n",
            "Training model 3\n",
            "Target Epsilon: 0.9\n",
            "Epoch 1/5\n",
            "Loss: 1.444394\n",
            "ε = 0.44, Accuracy: 90.00%\n",
            "\n",
            "Epoch 2/5\n",
            "Loss: 1.372313\n",
            "ε = 0.59, Accuracy: 90.00%\n",
            "\n",
            "Epoch 3/5\n",
            "Loss: 1.664380\n",
            "ε = 0.70, Accuracy: 90.00%\n",
            "\n",
            "Epoch 4/5\n",
            "Loss: 1.608755\n",
            "ε = 0.80, Accuracy: 90.00%\n",
            "\n",
            "Epoch 5/5\n",
            "Loss: 1.596174\n",
            "ε = 0.90, Accuracy: 90.00%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Application of Federated Learning with Flower"
      ],
      "metadata": {
        "id": "hn3e_yEJdT5k"
      },
      "id": "hn3e_yEJdT5k"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the required Flower libraries."
      ],
      "metadata": {
        "id": "104wo732dZ4u"
      },
      "id": "104wo732dZ4u"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flwr\n",
        "!pip install -U \"flwr[simulation]\""
      ],
      "metadata": {
        "id": "d4eiVwgmdb2Z"
      },
      "id": "d4eiVwgmdb2Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import flwr\n",
        "from flwr import *\n",
        "from flwr.common import *\n",
        "from flwr.client import *\n",
        "from flwr.server import *\n",
        "from collections import OrderedDict\n",
        "from flwr.server.strategy import FedAvg\n",
        "from flwr.simulation import run_simulation"
      ],
      "metadata": {
        "id": "BPknZdOKddYj"
      },
      "id": "BPknZdOKddYj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Added the required model fit evaluation functions for the FedAvg method."
      ],
      "metadata": {
        "id": "7k265Ft0dfP6"
      },
      "id": "7k265Ft0dfP6"
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_average_fit(metrics):\n",
        "  total_samples = sum([num_samples for num_samples, _ in metrics])\n",
        "  if total_samples == 0:\n",
        "    return {}\n",
        "  weighted_loss = sum(num_samples * metric.get(\"loss\", 0) for num_samples, metric in metrics) / total_samples\n",
        "  return {\"loss\" : weighted_loss}\n",
        "\n",
        "def weighted_average_evaluate(metrics):\n",
        "  total_samples = sum([num_samples for num_samples, _ in metrics])\n",
        "  if total_samples == 0:\n",
        "    return {}\n",
        "  weighted_loss = sum(num_samples * metric.get(\"loss\", 0) for num_samples, metric in metrics) / total_samples\n",
        "  weighted_accuracy = sum(num_samples * metric.get(\"accuracy\", 0) for num_samples, metric in metrics) / total_samples\n",
        "  return {\"loss\" : weighted_loss, \"accuracy\" : weighted_accuracy}"
      ],
      "metadata": {
        "id": "Fa7c-23sdlAT"
      },
      "id": "Fa7c-23sdlAT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implemented the FlowerClient class and its corresponding functions for FL."
      ],
      "metadata": {
        "id": "0Dq_QOyAdnhV"
      },
      "id": "0Dq_QOyAdnhV"
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(flwr.client.NumPyClient):\n",
        "    def __init__(self, model, train_dataset):\n",
        "        self.model = model\n",
        "        self.train_dataset = train_dataset\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = self.model.to(self.device)\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.tensor(v, device=self.device) for k, v in params_dict})\n",
        "        self.model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        self.set_parameters(parameters)\n",
        "        train_loader = DataLoader(self.train_dataset, batch_size=32, shuffle=True)\n",
        "        optimizer = torch.optim.SGD(self.model.parameters(), lr=0.01)\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        cumulative_loss = 0\n",
        "\n",
        "        for _ in range(5):  # Local epochs\n",
        "            for batch in train_loader:\n",
        "                optimizer.zero_grad()\n",
        "                X, y = batch\n",
        "                X, y = X.to(self.device), y.to(self.device)\n",
        "                outputs = self.model(X)\n",
        "                loss = criterion(outputs, y)\n",
        "                cumulative_loss += loss.item()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        avg_loss = cumulative_loss / len(train_loader)\n",
        "        return self.get_parameters(config={}), len(self.train_dataset), {\"loss\": avg_loss}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        self.set_parameters(parameters)\n",
        "        test_loader = DataLoader(self.train_dataset, batch_size=32)\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        loss = 0\n",
        "        accuracy = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                X, y = batch\n",
        "                X, y = X.to(self.device), y.to(self.device)\n",
        "                outputs = self.model(X)\n",
        "                loss += criterion(outputs, y).item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += y.size(0)\n",
        "                accuracy += (predicted == y).sum().item()\n",
        "\n",
        "        return loss, len(self.train_dataset), {\"loss\": loss / len(test_loader), \"accuracy\": accuracy / total}\n",
        "\n",
        "def client_fn(context: Context):\n",
        "    hospital_idx = 0 if context.node_id == '0' else 1 if context.node_id == '1' else 2\n",
        "    model = torch.nn.Sequential(\n",
        "        torch.nn.Linear(X.shape[1], 128),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(128, 2)\n",
        "    )\n",
        "    return FlowerClient(model, hospitals_in_torch[hospital_idx]).to_client()\n",
        "\n",
        "\n",
        "def server_fn(context: Context):\n",
        "    server_config = ServerConfig(num_rounds=3)\n",
        "    strategy = FedAvg(\n",
        "        fit_metrics_aggregation_fn=weighted_average_fit,\n",
        "        evaluate_metrics_aggregation_fn=weighted_average_evaluate,\n",
        "    )\n",
        "    return ServerAppComponents(\n",
        "        strategy=strategy,\n",
        "        config=server_config,\n",
        "    )\n"
      ],
      "metadata": {
        "id": "tbiKpxpcdtcf"
      },
      "id": "tbiKpxpcdtcf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tests the FL based approach."
      ],
      "metadata": {
        "id": "Yqd_njWddudA"
      },
      "id": "Yqd_njWddudA"
    },
    {
      "cell_type": "code",
      "source": [
        "client_app = ClientApp(client_fn=client_fn)\n",
        "server_app = ServerApp(server_fn=server_fn)\n",
        "\n",
        "run_simulation(\n",
        "    server_app=server_app,\n",
        "    client_app=client_app,\n",
        "    num_supernodes=3,\n",
        "    backend_config={\"client_resources\": {\"num_cpus\": 2, \"num_gpus\": 1}}\n",
        ")"
      ],
      "metadata": {
        "id": "y1wt_mzTdyzy"
      },
      "id": "y1wt_mzTdyzy",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}